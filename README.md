# VoxAI - Chat IA CatÃ³lica âœï¸ğŸ¤–

## DescriÃ§Ã£o do Projeto ğŸ“–
O **VoxAI** Ã© um chatbot de inteligÃªncia artificial voltado para fornecer informaÃ§Ãµes precisas e confiÃ¡veis sobre a doutrina catÃ³lica.  
Ele tem como objetivo central combater a desinformaÃ§Ã£o que circula sobre a Igreja CatÃ³lica, consultando diretamente documentos oficiais como:

- ğŸ“œ**Catecismo da Igreja CatÃ³lica**
- âš–ï¸**CÃ³digo de Direito CanÃ´nico**
- âœ‰ï¸**EncÃ­clicas papais**
- ğŸ“–**BÃ­blia CatÃ³lica**
- ğŸ›ï¸Outros documentos oficiais e relevantes da Igreja

O sistema lÃª PDFs de documentos importantes, processa seus trechos e utiliza embeddings para buscar respostas precisas Ã s perguntas dos usuÃ¡rios. Todas as respostas sÃ£o baseadas nos documentos originais, citando artigos, cÃ¢nones ou versÃ­culos bÃ­blicos quando aplicÃ¡vel.

---

## Estrutura do Projeto ğŸ“‚

```
voxAI/
â”‚
â”œâ”€â”€ backend/          # CÃ³digo da API FastAPI
â”‚   â””â”€â”€ app.py        # ExpÃµe a funÃ§Ã£o responder_com_documentos para o frontend
â”‚
â”œâ”€â”€ frontend/         # Frontend React com Vite
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.jsx
â”‚       â”œâ”€â”€ main.jsx
â”‚       â””â”€â”€ components/
â”‚           â”œâ”€â”€ Chat.jsx
â”‚           â””â”€â”€ Message.jsx
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ pdfs/ (ContÃ©m todos os pdfs para consulta de informaÃ§Ã£o)
â”‚
â”œâ”€â”€ embeddings/
â”‚   â””â”€â”€ embeddings.pkl (gerado automaticamente)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chat.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”œâ”€â”€ pdf_processor.py
â”‚   â””â”€â”€ vector_db.py
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```
---

## ConfiguraÃ§Ã£o âš™ï¸

1. **InstalaÃ§Ã£o das dependÃªncias**:

```bash
pip install -r requirements.txt
```

2. **ConfiguraÃ§Ã£o da API Key do OpenAI**:

No arquivo src/config.py, coloque sua chave da OpenAI:
```python
OPENAI_API_KEY = "sua_api_key_aqui"
```

3. **PDFs** ğŸ“„
Coloque todos os PDFs oficiais da Igreja em `data/pdfs/`.

4. **Embeddings** ğŸ§ 
O arquivo `embeddings/embeddings.pkl` Ã© gerado automaticamente pelo projeto na primeira execuÃ§Ã£o e **nÃ£o precisa ser enviado ao GitHub**.  
Ele contÃ©m os vetores de embeddings de todos os trechos dos PDFs.

## Como Funciona âš¡

### ExtraÃ§Ã£o de texto dos PDFs ğŸ“„
Cada PDF Ã© lido e seu conteÃºdo Ã© dividido em **chunks** de tamanho definido (`CHUNK_SIZE = 500 palavras`).

### CriaÃ§Ã£o de embeddings ğŸ§ 
Cada chunk Ã© transformado em um vetor numÃ©rico usando o modelo `text-embedding-ada-002` da OpenAI.  
Esses vetores permitem buscar trechos relevantes de acordo com a pergunta do usuÃ¡rio.

### Busca por relevÃ¢ncia ğŸ”
Quando uma pergunta Ã© feita, um embedding da pergunta Ã© criado e comparado com os embeddings dos trechos usando **similaridade cosseno**.  
SÃ£o selecionados os `TOP_K` trechos mais relevantes para formar o contexto.

### GeraÃ§Ã£o da resposta ğŸ“
O prompt enviado ao modelo ChatGPT inclui os trechos relevantes e instruÃ§Ãµes detalhadas para que a IA responda:

- Cite sempre o documento e o nÃºmero do artigo/cÃ¢non ou versÃ­culo.
- Coloque trechos literais entre **aspas duplas**.
- FaÃ§a um resumo simples e compreensÃ­vel.
- Nunca invente referÃªncias.

### HistÃ³rico de conversas ğŸ—‚ï¸
O chat mantÃ©m o histÃ³rico das interaÃ§Ãµes, permitindo respostas mais contextualizadas ao longo da conversa.

## Executando o Chat â–¶ï¸

### 1. Iniciando o Backend (Python)

No terminal, dentro da pasta do projeto `(chatVatican/)`:

```bash
python -m uvicorn backend.app:app --reload
```

- O backend ficarÃ¡ rodando em `http://127.0.0.1:8000`.
- Este serviÃ§o Ã© responsÃ¡vel por receber suas perguntas e enviar respostas baseadas nos PDFs da Igreja.

### 2. Iniciando o Frontend (React)

No terminal, dentro da pasta `frontend/`:

```bash
npm install
npm run dev
```

- O frontend abrirÃ¡ em algo como `http://127.0.0.1:5173` ou a porta indicada no terminal.
- Aqui vocÃª verÃ¡ a interface do chat, com o histÃ³rico de mensagens e um campo para digitar perguntas.

### 3. Como usar

- Digite sua pergunta no campo de texto do chat e pressione **Enter** ou clique em **Enviar**.
- A resposta do VoxAI serÃ¡ exibida logo abaixo.
- Para encerrar, basta fechar a janela do navegador ou o terminal.

## ConfiguraÃ§Ãµes Importantes âš™ï¸

No `src/config.py`:

```python
OPENAI_API_KEY = "sua_api_key"
PDF_PATH = "data/pdfs"          # Local dos PDFs
EMBEDDINGS_PATH = "embeddings/embeddings.pkl"
CHUNK_SIZE = 500                # NÃºmero de palavras por chunk
TOP_K = 3                       # NÃºmero de trechos relevantes usados por pergunta
```

## ObservaÃ§Ãµes â„¹ï¸

- **SeguranÃ§a** ğŸ”’: PDFs e embeddings nÃ£o sÃ£o versionados no GitHub.

- **PrecisÃ£o** âœ…: As respostas sÃ£o baseadas exclusivamente nos PDFs fornecidos.

- **Extensibilidade** â•: Ã‰ possÃ­vel adicionar novos PDFs Ã  pasta `data/pdfs` e o sistema atualizarÃ¡ os embeddings automaticamente na primeira execuÃ§Ã£o.
